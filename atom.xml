<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://saseke.github.io</id>
    <title>Smy</title>
    <updated>2022-07-15T06:59:09.358Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://saseke.github.io"/>
    <link rel="self" href="https://saseke.github.io/atom.xml"/>
    <subtitle>A student who is constantly striving</subtitle>
    <logo>https://saseke.github.io/images/avatar.png</logo>
    <icon>https://saseke.github.io/favicon.ico</icon>
    <rights>All rights reserved 2022, Smy</rights>
    <entry>
        <title type="html"><![CDATA[PR]]></title>
        <id>https://saseke.github.io/post/pr/</id>
        <link href="https://saseke.github.io/post/pr/">
        </link>
        <updated>2022-07-09T06:47:29.000Z</updated>
        <content type="html"><![CDATA[<h1 id="0">0.</h1>
<ol>
<li>在新建项目完成之后，先点击窗口，点击工作区，选择编辑以及重制为保存的布局。</li>
</ol>
<h1 id="1-时间线窗口操作">1. 时间线窗口操作</h1>
<h2 id="11-放大音频轨道查看波形">1.1 放大音频轨道，查看波形</h2>
<p>Alt + 滚轮滑动</p>
<h2 id="12-添加转场动画">1.2 添加转场动画</h2>
<ol>
<li>最快捷的方式：指针指向分割处，ctrl+d 就可以添加。</li>
<li>如果想自定义，可以打开效果进行设置自己想要的效果图。</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[New Java version of new feature]]></title>
        <id>https://saseke.github.io/post/new-java-version-of-new-feature/</id>
        <link href="https://saseke.github.io/post/new-java-version-of-new-feature/">
        </link>
        <updated>2022-07-05T08:24:02.000Z</updated>
        <content type="html"><![CDATA[<h1 id="1-java-9">1. Java 9</h1>
<p>Java 9 主要引入了 <font color='red'>模块化开发</font> ，JShell ,接口支持私有化，加强钻石操作符，try优雅关闭资源，修改String存储结构，快速创建可读集合，输入流直通输出流新特性。</p>
<h2 id="模块化开发">模块化开发</h2>
<p>对于开发者来说，没多大卵用。</p>
<h2 id="11-jshell工具">1.1 JShell工具</h2>
<p>JShell类似于Python等语言的交互式工具，可以不用创建Java文件，就可以编写一些简单的Java程序。</p>
<h2 id="12-接口支持私有化方法">1.2 接口支持私有化方法</h2>
<p>Java 8接口中引入了static,default方法。Java 9 接口中引入了私有的方法。</p>
<h2 id="13-java9加强钻石操作符">1.3 Java9加强钻石操作符</h2>
<p>Java 9 支持匿名内部类和钻石操作符同时使用。钻石操作符即 <code>&lt;&gt;</code>。</p>
<pre><code class="language-java">// Java 8
Comparator&lt;Object&gt; comparator = new Comparator&lt;&gt;() {
    @Override
    public int compare(Object o1, Object o2) {
        return 0;
    }
};
// 编译报错信息：Cannot use “&lt;&gt;” with anonymous inner classes

// Java 9
    @Test
    public void test2() {
        //钻石操作符与匿名内部类在java 8中不能共存。在java9可以。
        Comparator&lt;Object&gt; com = new Comparator&lt;&gt;() {
            @Override
            public int compare(Object o1, Object o2) {
                return 0;
            }
        };

        //jdk7中的新特性：类型推断
        ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;();

    }
</code></pre>
<h2 id="14-try关闭资源">1.4 try关闭资源</h2>
<p>Java 9 中 try 关闭资源更加容易。在 try 后边的小括号中填入资源即可，资源与资源之间通过 ; 进行分隔。</p>
<pre><code class="language-java">InputStreamReader reader = new InputStreamReader(System.in); 
OutputStreamWriter writer = new OutputStreamWriter(System.out); 
try (reader; writer) { 
    //reader是final的，不可再被赋值 
    //reader = null; 
    //具体读写操作省略 
} catch (IOException e) { 
    e.printStackTrace(); 
}
</code></pre>
<h2 id="15-string存储结构">1.5 String存储结构</h2>
<p>Java 8 中String类型数据，本质是 char 数组存储的。Java 9 中直接使用 byte 数组 + 编码方式进行存储。</p>
<h2 id="16-快速创建只读集合数据">1.6 快速创建只读集合数据</h2>
<pre><code class="language-java"> List&lt;Integer&gt; list1 = List.of(1, 2, 3, 4, 5);
//不能添加
// list1.add(6);
 System.out.println(list1);
Set&lt;Integer&gt; set1 = Set.of(23, 3, 54, 65, 43, 76, 87, 34, 46);
//不能添加
// set1.add(4);
System.out.println(set1);

 Map&lt;String, Integer&gt; map1 = Map.of(&quot;Tom&quot;, 23, &quot;Jerry&quot;, 54, &quot;HanMeimei&quot;, 12);
 //不能添加
// map1.put(&quot;Lilei&quot;,34);
System.out.println(map1);
 Map&lt;String, Integer&gt; map2 = Map.ofEntries(Map.entry(&quot;Tom&quot;, 34), Map.entry(&quot;Jerry&quot;, 21));
// map2.put(&quot;Lilei&quot;,34);
 System.out.println(map2);
</code></pre>
<h2 id="17-输入流-输出流">1.7 输入流-&gt;输出流</h2>
<p>Java 9 引入了 tranferTo() 方法，InputStream 数据可以直接到 OutputStream。</p>
<pre><code class="language-java">InputStream inputStream = new FileInputStream(&quot;a.txt&quot;);
OutputStream outputStream = new FileOutputStream(&quot;b.txt&quot;);
try (inputStream; outputStream) {
      inputStream.transferTo(outputStream);
} catch (IOException e) {
      e.printStackTrace();
}
</code></pre>
<h1 id="2-java-10">2. Java 10</h1>
<p>Java 10 最大的变化是引入了自动类型推断，类似于 C++ 里面的 <code>auto</code>。</p>
<h2 id="21-局部变量类型推断">2.1 局部变量类型推断</h2>
<p>Java可以通过 <code>var</code> 来简化变量的返回值。</p>
<pre><code class="language-java">public class Test {

    public static List&lt;String&gt; getList() {
        return List.of(&quot;hello&quot;, &quot;world&quot;);
    }

    public static void main(String[] args) {
        var list1 = new ArrayList&lt;&gt;();
        var list2 = getList();
    }
}
</code></pre>
<h1 id="3-java-11">3. Java 11</h1>
<h2 id="31-string新方法">3.1 String新方法</h2>
<ol>
<li>isBlank()<br>
判断字符串是否全是空格组成的字符串。如果字符串是多个空格组成，最后也会是判断为 true。</li>
<li>strip()<br>
去除字符串左侧和右侧的全部空格。如果字符串左侧或者右侧有多个空格，最后也都会删除掉。</li>
<li>stripLeading()<br>
去除字符串左侧的全部空格。</li>
<li>stripTrailing()<br>
去除字符串右侧的全部空格。</li>
<li>lines()<br>
分割字符串，最后变成字符串流。字符串分割会根据 <code>\n</code>来进行分割。</li>
<li>repeat()<br>
重复指定字符串。</li>
</ol>
<h2 id="32-http-client">3.2 HTTP Client</h2>
<p>Java 的 HTTP Client 支持 HTTP/1.1 和 HTTP/2。支持同步和异步调用HTTP Client。</p>
<h3 id="33-java-飞行记录器-java-flight-recorder">3.3 Java 飞行记录器 (Java Flight Recorder)</h3>
<p>JFR 是一个性能分析工具。JFR可以实现在运行的 Java 程序中收集诊断数据和分析数据。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[天平之甍-井上靖]]></title>
        <id>https://saseke.github.io/post/tian-ping-zhi-meng-jing-shang-jing/</id>
        <link href="https://saseke.github.io/post/tian-ping-zhi-meng-jing-shang-jing/">
        </link>
        <updated>2022-07-01T05:02:04.000Z</updated>
        <content type="html"><![CDATA[<p>普照：身材矮小，瘦弱，比荣睿年轻两岁<br>
荣睿：结实，不刮胡子，30出头。渴望尽其所能，学到更多的佛教知识<br>
玄朗：比戒融小两三岁，容貌端正，言行颇有气质。自己想回家<br>
戒融：与普照同年，体格高达，显得傲慢，会说唐语。刚入大福先寺时，期望自己能够踏遍中国每一处</p>
<h1 id="第一章">第一章</h1>
<p><strong>公元733年（天平5年，开元21年）</strong></p>
<p><strong>二月初</strong>，普照，荣睿被派做渡唐留学僧<br>
<strong>闰三月26日</strong>：大使广成入朝接受节刀<br>
<strong>四月二日</strong>：广成，普照，荣睿从奈良出发，前往难波津（大阪地区的一个港口）距离42km<br>
<img src="https://saseke.github.io/post-images/1656681769955.png" alt="" loading="lazy"><br>
<strong>四月三日</strong>：分成四队，坐四艘船从难波三津浦（大阪市南区三津寺町）出发，之后到达本土最后一个港口：大津浦（今博多）。接下来就离开本土前往唐<br>
<img src="https://saseke.github.io/post-images/1656683180300.png" alt="" loading="lazy"><br>
<strong>当时前往唐的路线</strong><br>
北路：初期遣唐使的航线大致是摸着朝鲜半岛海岸线抵达大唐的，形成后人所称的“北路”（630-671年）：从日本出发后，经由朝鲜南畔与聃罗国（济州岛）之间，到达现在的韩国仁川附近，然后或直渡黄海，或沿朝鲜半岛的西岸及辽东半岛的东岸，横渡渤海湾口。最终遣唐船舶在山东半岛一角登陆。北部中途停泊点多，有助于沿途补给，大大提高了安全性。<br>
南路：遣唐使却“冷不丁”地修改了航行路线，更改的这条路线被称为“南路”（672-894年）：或是从筑紫的西岸南下，经过南岛，横渡东中国海，漂至以扬子江为衷心的杨洲与苏州之间<br>
<img src="https://saseke.github.io/post-images/1656686271900.jpg" alt="" loading="lazy"></p>
<blockquote>
<p>好端端的北路不走，走南路？<br>
朝鲜半岛三国时代（公元427-公元660年）高句丽，百济，新罗形成三国鼎力。在公元668年新罗在唐朝帮助下征服百济，后灭高句，结束了三国时代，进入统一新罗时代。成为了岛上一霸的新罗，无意顾忌与日本的关系，对途径的日本船队便换了一副脸面，仗势凌人，还从中作梗。这才迫使日本下定决心，改道南路，横渡大海。</p>
</blockquote>
<p><strong>四月末</strong>,开始自大津浦航向外海，一开始大家都晕船，20日之后遭遇浓雾，巨浪，暴雨袭击。<br>
<strong>八月</strong>，四艘船只都到达苏州海岸。</p>
<p><strong>公元734年 (天平6年，开元22年)</strong></p>
<p><strong>四月</strong> ， 一行人到达洛阳，（此时唐玄宗在洛阳），之后都呆在了大福先寺庙进行学习。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Hadoop Distributed File System]]></title>
        <id>https://saseke.github.io/post/the-hadoop-distributed-file-system/</id>
        <link href="https://saseke.github.io/post/the-hadoop-distributed-file-system/">
        </link>
        <updated>2022-06-20T14:28:10.000Z</updated>
        <content type="html"><![CDATA[<h1 id="论文前置知识">论文前置知识</h1>
<ol>
<li>文件系统的Namespace是什么<br>
Namespace是文件系统目录的组织方式</li>
</ol>
<h1 id="论文正文">论文正文</h1>
<h2 id="hadoop简述">Hadoop简述</h2>
<p>Hadoop是Apache 开源的一个项目。Hadoop提供了一个分布式文件系统(HDFS)以及一个分布式计算框架(MapReduce)。Hadoop最大的特点就是：数据分散在许多机器上存储，多台机器并行计算。</p>
<h2 id="hdfs架构">HDFS架构</h2>
<p>HDFS主要由NameNodes,DataNodes，HDFS Client,Image,Journal,CheckpointNode,BackupNode,Upgrades,File System Snapshots.构成</p>
<h3 id="namenode相关知识">NameNode相关知识</h3>
<ol>
<li>HDFS的Namespace是由文件和目录构成的层次结构。HDFS中用inode表示File和Directories。<font color='red'>意思是除了文件和目录表示文件之外，还有其他存储文件的方式</font></li>
<li>inode中存储了文件权限，修改和访问时间，namespace,磁盘空间的分配等信息。</li>
<li>HDFS的文件数据内容被拆分成许多large blocks(通常是128 MB)。每一个文件块都可以单独配置副本数。</li>
<li>Namenode存储了namespace tree和 File Blocks与存储它的DataNodes的映射</li>
<li>HDFS Client 读取数据的过程<br>
(1) HDFS Client首先会向NameNode询问文件对应的数据块的位置<br>
(2)HDFS Cliet 从距离自己最近的DataNode读取数据</li>
<li>HDFS Client 写入数据的过程<br>
(1) HDFS Client 请求NameNode，NameNode返回给合适的三个DataNodes给Client<br>
(2)HDFS Client 以流水线的方式将数据写入三个DataNodes中</li>
<li>image概念<br>
inode数据和构成每一个文件的块列表集合共同组成了NameNode的元数据：Image</li>
<li>checkpoint概念<br>
将Image数据存储到文件系统中，进行持久化后的文件叫做checkpoint</li>
<li>journal概念<br>
对Image各种操作的log日志文件叫做:journal</li>
<li>namespace信息存储在RAM中</li>
</ol>
<h3 id="datanodes">DataNodes</h3>
<ol>
<li>DataNodes主要是由许多等大小的Blocks构成。每一个Block分成两部分，一部分是文件本身的数据，另外一部分是Block的元数据，比如：校验和,生成戳</li>
<li>DataNode在连接NameNode之后，会向NameNode执行一次<code>handshake</code>即握手。握手的目的是校验namespace ID和软件版本是否与NameNode对应。如果不对应，就停止DataNode</li>
<li>namespace ID:在文件系统格式化的时候，会重新分配。通过使用namespace ID来验证DataNode是否属于该集群中</li>
<li>当一个没有namespace ID的DataNode加入集群时候，会将当前集群的namespace ID 分配给它</li>
<li>除了分配namespace ID之外，DataNode还会自动生成一个storage ID来进行内部标示。这个ID标示可以有效的防止IP,PORT变换之后的识别</li>
<li>副本确认：DataNode每隔一个小时发送<code>block report</code>将自己拥有的块信息发送给NameNode。发送的信息包括: block id, 生成戳,每一个数据块的长度。</li>
<li>心跳机制：DataNode每三秒会向NameNode发送心跳报文。如果NameNode超过10分钟还没有收到DataNode的心跳，NameNode会将该DataNode存储的Block数据备份复制到别的机器上</li>
<li>metadata数据：DataNode发送心跳的时候，也会发送一些metadata数据。如：磁盘总容量，磁盘使用情况，当前数据传输进度等数据。NameNode拿到这些数据之后，方便进行决策</li>
<li>NameNode通过对心跳的回应，来为DataNode下发命令。命令包括：复制blocks到其他的nodes,删除本地的blocks,重新注册等命令。</li>
</ol>
<h3 id="hdfs-client">HDFS Client</h3>
<p><strong>HDFS Client读取数据</strong></p>
<ol>
<li>询问Namenode，获取到文件块存放的DataNodes</li>
<li>直接请求对应的DataNodes，获取数据</li>
</ol>
<p><strong>HDFS Client写入数据</strong><br>
流程就是：写完一个块，再写另外一个块</p>
<ol>
<li>HDFS Client询问Namenode获取一个适合存放文件的DataNode</li>
<li>HDFS Client使用pipline建立与DataNode的数据通信，进行块数据传输</li>
<li>传输完第一个块之后，HDFS Client再向Namenode请求下一个块适合存放的DataNode位置 ...</li>
</ol>
<h3 id="image-and-journal">Image and Journal</h3>
<p><strong>checkpoint是什么</strong><br>
将HDFS的image持久化的文件数据叫做checkpoint<br>
<strong>特点</strong></p>
<ol>
<li>checkpoint数据不会被NameNode进行修改</li>
<li>checkpoint的更新是在下一次NameNode重启的时候</li>
</ol>
<p><strong>checkpoint更新规则</strong></p>
<ol>
<li>在NameNode重启之后，读取checkpoint数据，形成新的checkpoint</li>
<li>将新的checkpoint和空的journal写回磁盘</li>
</ol>
<h3 id="checkpointnode">CheckpointNode</h3>
<p><strong>CheckpointNode本质</strong><br>
本质就是NameNode,NameNode除了处理Client的请求之外，还可以扮演CheckpointNode和BackupNode两个角色。<br>
<strong>CheckpointNode职责</strong><br>
Checkpoint负责从Namenode上拉取Checkpoint和Journal信息，然后将Checkpoint和Journal合并成一个新的Checkpoint，和空的Journal文件同步返回给NameNode。<br>
<strong>为什么设置CheckpointNode</strong><br>
防止Journal日志过大，对系统运行产生影响</p>
<h3 id="backupnode">BackupNode</h3>
<p><strong>BackupNode本质</strong><br>
是一个NameNode的副本，而且所有的数据全都存储在BackupNode的内存中</p>
<h2 id="file-read-and-write">File Read and Write</h2>
<p><strong>文件最重要的两个特点</strong></p>
<ol>
<li>数据一旦写入，就不可以更新和删除，只能进行追加数据</li>
<li>HDFS是采用单线程写入，多线程读的线程模型</li>
</ol>
<p><strong>多个线程同时写入一个文件，HDFS执行流程</strong></p>
<ol>
<li>写文件的Client会周期性的向Namenode发送心跳，进行续租。</li>
<li>租约有soft limti和hard limit,在soft limit期间，该文件只能由该Client进行写入，其他线程进不去。如果超出了soft limit但是没有超出hard limit,那么其他线程可以抢写入该文件的机会。在超过hard limit时间之后，那么HDFS会主动关闭该文件，认为没有线程写入该文件。</li>
</ol>
<p><strong>HDFS写入数据的流程</strong></p>
<ol>
<li>请求NameNode分配对应的Block</li>
<li>NameNode选择合适的DataNodes存储Block副本</li>
<li>多个DataNodes之间构成一个pipline,进行数据传输</li>
</ol>
<p><strong>数据一致性</strong><br>
HDFS的文件数据是在写入完成整个文件之后，才对其他Reader可见。在写入的过程中是不可见的。如果想要在写入的过程中，写入的内容对其他Reader可见，就可以使用<code>hflush</code>操作进行数据一致性。</p>
<h1 id="碰到的问题">碰到的问题</h1>
<ol>
<li>HDFS的文件块为什么设置的这么大<br>
(1) 文件块大，对应的inode数据就少，文件的元数据就少<br>
(2)减少文件块的寻址时间</li>
<li>Client写入数据，数据是在哪里进行分块的<br>
(1)个人猜测：是在以pipline写入数据的时候，DataNode做的分块处理</li>
<li>Client以流水线的方式写入三个DataNodes中。假设一个文件被拆分成5个Block块，那么5块都是在一个DataNode上进行部署的吗？三个DataNodes存储的是相同的数据？<br>
HDFS最初设计为啥只设计一个NameNode</li>
<li>namespace ID作用是什么？<br>
​	通过namespace ID来判断DataNode是否属于该集群</li>
<li>向DataNode写入数据，对文件的分块操作谁来做，怎么将文件写入对应block中去<br>
通过HDFS Client将数据分块，每一块都单独传输</li>
<li>为什么将每一个文件块的副本设置为3?</li>
<li>多线程条件下，多个Client提交事物，为什么在sync-flush阶段，变成顺序执行了<br>
因为多个线程最后存储的是同一个journal文件。文件肯定不支持并发写操作</li>
<li>HDFS为什么设计成数据只能追加？<br>
创建新文件，比更新旧文件速度快</li>
</ol>
<h1 id="点子">点子</h1>
<ol>
<li>对于那些重要的或者经常访问的，Block 副本数目可以增加,提高容错率</li>
<li>可以在HDFS Client端做一下块位置缓存，方便下次读取相同位置的数据，就不需要再次访问Namenode,减轻Namenode的压力</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Diary papers]]></title>
        <id>https://saseke.github.io/post/diary-papers/</id>
        <link href="https://saseke.github.io/post/diary-papers/">
        </link>
        <updated>2022-06-20T12:57:17.000Z</updated>
        <content type="html"><![CDATA[<h1 id="620">6.20</h1>
<h2 id="the-hadoop-distributed-file-system-论文相关知识">The Hadoop Distributed File System 论文相关知识</h2>
<h3 id="论文前置知识">论文前置知识</h3>
<ol>
<li>文件系统的Namespace是什么<br>
Namespace是文件系统目录的组织方式</li>
</ol>
<p><strong>Hadoop简述</strong><br>
Hadoop是Apache 开源的一个项目。Hadoop提供了一个分布式文件系统(HDFS)以及一个分布式计算框架(MapReduce)。Hadoop最大的特点就是：数据分散在许多机器上存储，多台机器并行计算。</p>
<p><strong>HDFS架构</strong><br>
HDFS主要由NameNodes,DataNodes，HDFS Client,Image,Journal,CheckpointNode,BackupNode,Upgrades,File System Snapshots.构成</p>
<p><strong>NameNode相关知识</strong></p>
<ol>
<li>HDFS的Namespace是由文件和目录构成的层次结构。HDFS中用inode表示File和Directories。<font color='red'>意思是除了文件和目录表示文件之外，还有其他存储文件的方式</font></li>
<li>inode中存储了文件权限，修改和访问时间，namespace,磁盘空间的分配等信息。</li>
<li>HDFS的文件数据内容被拆分成许多large blocks(通常是128 MB)。每一个文件块都可以单独配置副本数。</li>
<li>Namenode存储了namespace tree和 File Blocks与存储它的DataNodes的映射</li>
<li>HDFS Client 读取数据的过程
<ul>
<li>HDFS Client首先会向NameNode询问文件对应的数据块的位置</li>
<li>HDFS Cliet 从距离自己最近的DataNode读取数据</li>
</ul>
</li>
<li>HDFS Client 写入数据的过程
<ul>
<li>HDFS Client 请求NameNode，NameNode返回给合适的三个DataNodes给Client</li>
<li>HDFS Client 以流水线的方式将数据写入三个DataNodes中</li>
</ul>
</li>
<li>image概念<br>
inode数据和构成每一个文件的块列表集合共同组成了NameNode的元数据：Image</li>
<li>checkpoint概念<br>
将Image数据存储到文件系统中，进行持久化后的文件叫做checkpoint</li>
<li>journal概念<br>
对Image各种操作的log日志文件叫做:journal</li>
<li>namespace信息存储在RAM中</li>
</ol>
<h3 id="碰到的问题">碰到的问题</h3>
<ol>
<li>HDFS的文件块为什么设置的这么大
<ul>
<li>文件块大，对应的inode数据就少，文件的元数据就少</li>
<li>减少文件块的寻址时间</li>
</ul>
</li>
<li>Client写入数据，数据是在哪里进行分块的
<ul>
<li>个人猜测：是在以pipline写入数据的时候，DataNode做的分块处理</li>
</ul>
</li>
<li>Client以流水线的方式写入三个DataNodes中。假设一个文件被拆分成5个Block块，那么5块都是在一个DataNode上进行部署的吗？三个DataNodes存储的是相同的数据？</li>
<li>HDFS最初设计为啥只设计一个NameNode</li>
</ol>
<h1 id="621">6.21</h1>
<h2 id="the-hadoop-distributed-file-system-论文相关知识-2">The Hadoop Distributed File System 论文相关知识</h2>
<p><strong>DataNodes</strong></p>
<ol>
<li>DataNodes主要是由许多等大小的Blocks构成。每一个Block分成两部分，一部分是文件本身的数据，另外一部分是Block的元数据，比如：校验和,生成戳</li>
<li>DataNode在连接NameNode之后，会向NameNode执行一次<code>handshake</code>即握手。握手的目的是校验namespace ID和软件版本是否与NameNode对应。如果不对应，就停止DataNode</li>
<li>namespace ID:在文件系统格式化的时候，会重新分配。通过使用namespace ID来验证DataNode是否属于该集群中</li>
<li>当一个没有namespace ID的DataNode加入集群时候，会将当前集群的namespace ID 分配给它</li>
<li>除了分配namespace ID之外，DataNode还会自动生成一个storage ID来进行内部标示。这个ID标示可以有效的防止IP,PORT变换之后的识别</li>
<li>副本确认：DataNode每隔一个小时发送<code>block report</code>将自己拥有的块信息发送给NameNode。发送的信息包括: block id, 生成戳,每一个数据块的长度。</li>
<li>心跳机制：DataNode每三秒会向NameNode发送心跳报文。如果NameNode超过10分钟还没有收到DataNode的心跳，NameNode会将该DataNode存储的Block数据备份复制到别的机器上</li>
<li>metadata数据：DataNode发送心跳的时候，也会发送一些metadata数据。如：磁盘总容量，磁盘使用情况，当前数据传输进度等数据。NameNode拿到这些数据之后，方便进行决策</li>
<li>NameNode通过对心跳的回应，来为DataNode下发命令。命令包括：复制blocks到其他的nodes,删除本地的blocks,重新注册等命令。</li>
</ol>
<h3 id="碰到的问题-2">碰到的问题</h3>
<ol>
<li>namespace ID作用是什么？<br>
通过namespace ID来判断DataNode是否属于该集群</li>
<li>向DataNode写入数据，对文件的分块操作谁来做，怎么将文件写入对应block中去<br>
通过HDFS Client将数据分块，每一块都单独传输</li>
</ol>
<h1 id="627">6.27</h1>
<h2 id="the-hadoop-distributed-file-system-论文相关知识-3">The Hadoop Distributed File System 论文相关知识</h2>
<h3 id="hdfs-client">HDFS Client</h3>
<p>HDFS Client主要就是用来与用户做交互使用的。</p>
<h1 id="628">6.28</h1>
<h2 id="the-hadoop-distributed-file-system-论文相关知识-4">The Hadoop Distributed File System 论文相关知识</h2>
<h3 id="hdfs-client-2">HDFS Client</h3>
<p><strong>HDFS Client读取数据</strong></p>
<ol>
<li>询问Namenode，获取到文件块存放的DataNodes</li>
<li>直接请求对应的DataNodes，获取数据</li>
</ol>
<p><strong>HDFS Client写入数据</strong><br>
流程就是：写完一个块，再写另外一个块</p>
<ol>
<li>HDFS Client询问Namenode获取一个适合存放文件的DataNode</li>
<li>HDFS Client使用pipline建立与DataNode的数据通信，进行块数据传输</li>
<li>传输完第一个块之后，HDFS Client再向Namenode请求下一个块适合存放的DataNode位置 ...</li>
</ol>
<h3 id="image-and-journal">Image and Journal</h3>
<h4 id="checkpoint">checkpoint</h4>
<p><strong>checkpoint是什么</strong><br>
将HDFS的image持久化的文件数据叫做checkpoint</p>
<p><strong>特点</strong></p>
<ol>
<li>checkpoint数据不会被NameNode进行修改</li>
<li>checkpoint的更新是在下一次NameNode重启的时候</li>
</ol>
<p><strong>checkpoint更新规则</strong></p>
<ol>
<li>在NameNode重启之后，读取checkpoint数据，形成新的checkpoint</li>
<li>将新的checkpoint和空的journal写回磁盘</li>
</ol>
<h3 id="遇到的问题">遇到的问题</h3>
<ol>
<li>为什么将每一个文件块的副本设置为3?</li>
</ol>
<h3 id="点子">点子</h3>
<ol>
<li>对于那些重要的或者经常访问的，Block 副本数目可以增加,提高容错率</li>
<li>可以在HDFS Client端做一下块位置缓存，方便下次读取相同位置的数据，就不需要再次访问Namenode,减轻Namenode的压力</li>
</ol>
<h1 id="629">6.29</h1>
<h2 id="the-hadoop-distributed-file-system-论文相关知识-5">The Hadoop Distributed File System 论文相关知识</h2>
<h3 id="checkpointnode">CheckpointNode</h3>
<p><strong>CheckpointNode本质</strong><br>
本质就是NameNode,NameNode除了处理Client的请求之外，还可以扮演CheckpointNode和BackupNode两个角色。<br>
<strong>CheckpointNode职责</strong><br>
Checkpoint负责从Namenode上拉取Checkpoint和Journal信息，然后将Checkpoint和Journal合并成一个新的Checkpoint，和空的Journal文件同步返回给NameNode。</p>
<p><strong>为什么设置CheckpointNode</strong><br>
防止Journal日志过大，对系统运行产生影响</p>
<h3 id="backupnode">BackupNode</h3>
<p><strong>BackupNode本质</strong><br>
是一个NameNode的副本，而且所有的数据全都存储在BackupNode的内存中</p>
<!-- File IO Operation And Replica management -->
<h3 id="file-read-and-write">File Read and Write</h3>
<p><strong>文件最重要的两个特点</strong></p>
<ol>
<li>数据一旦写入，就不可以更新和删除，只能进行追加数据</li>
<li>HDFS是采用单线程写入，多线程读的线程模型</li>
</ol>
<p><strong>多个线程同时写入一个文件，HDFS执行流程</strong></p>
<ol>
<li>写文件的Client会周期性的向Namenode发送心跳，进行续租。</li>
<li>租约有soft limti和hard limit,在soft limit期间，该文件只能由该Client进行写入，其他线程进不去。如果超出了soft limit但是没有超出hard limit,那么其他线程可以抢写入该文件的机会。在超过hard limit时间之后，那么HDFS会主动关闭该文件，认为没有线程写入该文件。</li>
</ol>
<p><strong>HDFS写入数据的流程</strong></p>
<ol>
<li>请求NameNode分配对应的Block</li>
<li>NameNode选择合适的DataNodes存储Block副本</li>
<li>多个DataNodes之间构成一个pipline,进行数据传输</li>
</ol>
<p><strong>数据一致性</strong><br>
HDFS的文件数据是在写入完成整个文件之后，才对其他Reader可见。在写入的过程中是不可见的。如果想要在写入的过程中，写入的内容对其他Reader可见，就可以使用<code>hflush</code>操作进行数据一致性。</p>
<h3 id="遇到的问题-2">遇到的问题</h3>
<ol>
<li>多线程条件下，多个Client提交事物，为什么在sync-flush阶段，变成顺序执行了<br>
因为多个线程最后存储的是同一个journal文件。文件肯定不支持并发写操作</li>
<li>HDFS为什么设计成数据只能追加？<br>
创建新文件，比更新旧文件速度快</li>
</ol>
<h1 id="630">6.30</h1>
<p><strong>HDFS Client读取block流程</strong></p>
<ol>
<li>HDFS Client会请求NameNode获取所有的块信息，以及对应块的副本位置</li>
<li>对于每一块数据，HDFS Client会把副本机器距离当前机器的距离进行排序，优先选择距离近的节点进行下载数据</li>
</ol>
<h1 id="74">7.4</h1>
<h3 id="block-placement">Block Placement</h3>
<p>确定数据块备份存放的节点位置。</p>
<ol>
<li>存放Block数据的节点存放在机架上面，每一个机架的节点共享一个交换机。机架与机架之前通过交换机进行连接。<br>
<img src="https://saseke.github.io/post-images/1656942388065.png" alt="" loading="lazy"></li>
<li>HDFS通过节点与节点之间的距离来计算网络带宽。两个节点的距离可以通过找到它们公共祖先来计算获得。</li>
<li>在DataNode向NameNode注册的时候，NameNode需要标识该DataNode属于哪个机架。</li>
</ol>
<p><strong>HDFS块放置策略</strong></p>
<ol>
<li>HDFS会将第一个副本放置在写请求方所在的DataNode。(Client第一个请求的DataNode)</li>
<li>HDFS将第二个，第三个放在另外一个机架上，但是不是相同的DataNode</li>
<li>剩下的副本存放在其他任意的节点上，但是要求每个机架最多有一个副本</li>
<li>如果数据的副本数目&lt;机架数目的2倍，可以要求每个机架最多有两个该数据的副本</li>
<li>在确定块的放置位置之后，DataNode会按照距离第一个DataNode的距离构成链状结构，构建pipline。进行数据传输</li>
</ol>
<p><strong>HDFS读取块数据</strong></p>
<ol>
<li>NameNode会根据Client选择的DataNode，拿到对应的Block存放的位置返还给Client端。</li>
</ol>
<h3 id="replication-management">Replication management</h3>
<p>提供对数据块副本数目的控制</p>
<ol>
<li>NameNode会监控每个Block的副本数目。</li>
<li>如果超过了约定的副本数目，NameNode会选择一个使用磁盘空间最多的那个DataNode，将Block数据删除掉。</li>
<li>如果少于约定的副本数目，NameNode会将创建副本任务放入优先级队列中。只有一个Block副本的优先级最高，副本越多，优先级越低。通过一个后台线程去获取优先级队列的第一个任务，去创建对应的块的副本。</li>
<li>NameNode也必须保证Block的所有副本不能全在一个node上。由于Block在其他机架上备份的数目少于要求的数目，因此会触发备份。当备份创建完成之后，Block的备份数目会大于要求的数目，从而需要进行旧备份的删除操作。</li>
</ol>
<h3 id="遇到的问题-3">遇到的问题</h3>
<ol>
<li>hflush看不懂呀<br>
hflush用来实现数据一致性的</li>
</ol>
<h3 id="点子-2">点子</h3>
<p>如果Block的副本很多的情况，还使用这种线性的pipline技术，很显然就很慢了。可以引入图的技术，进一步加快数据同步。</p>
<h2 id="hdfs局限性">HDFS局限性</h2>
<ol>
<li>HDFS不支持随机读写，文件一旦写入，不能改变，只能在原来的基础上进行追加操作</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Daily distributed file system design]]></title>
        <id>https://saseke.github.io/post/distributed-file-system-design-diary/</id>
        <link href="https://saseke.github.io/post/distributed-file-system-design-diary/">
        </link>
        <updated>2022-06-20T11:28:06.000Z</updated>
        <content type="html"><![CDATA[<h1 id="620">6.20</h1>
<p><strong>c语言的strcmp使用</strong><br>
功能：字符串比较<br>
参数：待比较的两个字符串<br>
返回值：如果相等，返回0；如果s1&gt;s2 返回&gt;0的数字，如果s1&lt;s2,返回&lt;0的数字</p>
<p><strong>今日学习</strong></p>
<ol>
<li>了解了如何将文件写入到文件中。</li>
<li>了解如何将文件读出到buffer中。</li>
</ol>
<p><strong>遇到的问题</strong></p>
<ol>
<li>在读取文件数据到buffer.txt中的时候，为什么要回收磁盘数据呢<br>
答案：方便数据的写回。在数据写回的时候，直接获取到空闲的盘块，直接写入数据就行，不需要考虑文件原来占用了哪些盘块</li>
</ol>
<h1 id="624">6.24</h1>
<p><strong>新需求</strong></p>
<p>文件权限相关信息</p>
<h1 id="627">6.27</h1>
<ol>
<li>定义好Super_Block,Inode,Data_block的数据结构</li>
<li>写好init_system,exit_system的代码</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Daily algorithm knowledge record]]></title>
        <id>https://saseke.github.io/post/daily-algorithm-knowledge-record/</id>
        <link href="https://saseke.github.io/post/daily-algorithm-knowledge-record/">
        </link>
        <updated>2022-06-20T01:43:09.000Z</updated>
        <content type="html"><![CDATA[<h1 id="620">6.20</h1>
<h2 id="1-十进制转二进制-代码实现">1. 十进制转二进制。代码实现</h2>
<p><strong>实现逻辑:</strong></p>
<ol>
<li>获取最后一位，判断是1还是0</li>
<li>向右移动一位</li>
</ol>
<p><strong>代码：</strong></p>
<pre><code class="language-c++">void tenToBinary(int n) {
    string ans;
    while (n &gt; 0) {
        ans.push_back((n &amp; 1) + '0');
        n = n &gt;&gt; 1;
    }
    reverse(ans.begin(), ans.end());
    cout &lt;&lt; ans &lt;&lt; endl;
}
</code></pre>
<h2 id="2-高效实现powxn">2. 高效实现Pow(x,n)</h2>
<p>可以通过<strong>快速幂</strong>来实现Pow(x,n)。时间复杂度 O(logn)</p>
<p><strong>实现逻辑：</strong><br>
<img src="https://saseke.github.io/post-images/1656904399009.png" alt="" loading="lazy"></p>
<p><strong>代码：</strong></p>
<pre><code class="language-c++">double myPow(double x, int n) {
    if (x == 0 || x == 1) return x;
    if (n == 0) return 1;
    long nBak = n;
    if (nBak &lt; 0) {
        nBak = -nBak;
        x = 1 / x;
    }
    double ans = 1, weight = x;
    while (nBak != 0) {
        if ((nBak &amp; 1) == 1) {
            ans *= weight;
        }
        weight *= weight;
        nBak = nBak &gt;&gt; 1;
    }
    return ans;
}
</code></pre>
<p><strong>原题链接</strong><br>
<a href="https://leetcode.cn/problems/powx-n/">Pow(x,n)</a></p>
<h1 id="626">6.26</h1>
<h2 id="1-优先级队列实现堆排序">1. 优先级队列实现堆排序</h2>
<p>Java可直接使用<code>PriorityQueue</code>这个类来实现堆排序。</p>
<p><strong>代码</strong></p>
<pre><code class="language-java">  private PriorityQueue&lt;Integer&gt; queue;
    private int size;

    public int[] getLeastNumbers(int[] arr, int k) {
        int[] ans = new int[k];
        this.queue = new PriorityQueue&lt;&gt;((o1, o2) -&gt; o2 - o1);
        this.size = 0;

        if (k == 0)
            return ans;

        for(int element:arr){
            if(this.size==k){  // queue已经满了,如果堆顶元素&gt;element,poll,
                int topElement = queue.poll();
                queue.add(Math.min(topElement, element));
            } else {
                this.queue.add(element);
                this.size++;
             }
         }

         int index=0;
         while(!queue.isEmpty()){
             ans[index++] = queue.poll();
         }
        return ans;
    }
</code></pre>
<p><strong>优先级队列用途</strong></p>
<ul>
<li>求n个数中前k小</li>
<li>求n个数中前k大</li>
</ul>
<p><strong>原题链接</strong><br>
<a href="https://leetcode.cn/problems/zui-xiao-de-kge-shu-lcof/">最小的k个数</a></p>
<h1 id="74">7.4</h1>
<h2 id="1-若初始不知道数组大小如何分配数组">1. 若初始不知道数组大小，如何分配数组</h2>
<ol>
<li>如果知道初始化数组容量，可以直接在栈上进行内存分配</li>
</ol>
<pre><code class="language-c++">#define SIZE 10
int arr[SIZE];
</code></pre>
<ol start="2">
<li>如果不知道初始化数组容量，容量是通过函数变量获取的,可以通过在堆上进行内存分配</li>
</ol>
<pre><code class="language-c++">int *arr  = new int[n];
</code></pre>
<h2 id="遇到的问题">遇到的问题</h2>
<ol>
<li>根据测试数据的数目，大概判断什么时间复杂度的算法不会超时</li>
</ol>
<h1 id="79">7.9</h1>
<h2 id="1-字母和数字对应的ascii码">1. 字母和数字对应的ASCII码</h2>
<ol>
<li>数字的 ASCII 对应的数字: 48 - 57</li>
<li>大写字母的 ASCII 对应的数字: 65 - 90</li>
<li>小写字母的 ASCII 对应的数字: 97 - 122<br>
大写字母与小写字母中间差了 32</li>
</ol>
<h2 id="2-c-判断字符是数字字母">2. C++ 判断字符是数字，字母</h2>
<ol>
<li>判断数字: <code>isdigit()</code></li>
<li>判断字母: <code>isalpha()</code></li>
</ol>
<h1 id="714">7.14</h1>
<h2 id="1-二分查找使用">1. 二分查找使用</h2>
<p>二分查找除了普通的在有序数组中查找某个数字是否存在，也可以用在一些非有序的场景中去解决问题。</p>
<ol>
<li><a href="https://leetcode.cn/problems/find-the-duplicate-number/">287. 寻找重复数</a></li>
</ol>
<h2 id="2-trie前缀树-实现">2. Trie(前缀树) 实现</h2>
<p>每个节点都包含26个数据部分和一个标识是否为字符串终止的标识。</p>
<pre><code class="language-java">public class Test {
    public static void main(String[] args) {
        Trie trie = new Trie();
        trie.insert(&quot;apple&quot;);
        trie.search(&quot;apple&quot;);
    }
}

class Trie {
    private boolean isEnd;
    private Trie[] words;

    public Trie() {
        words = new Trie[26];
        isEnd = false;
    }

    public void insert(String word) {
        Trie cur = this;
        for (char c : word.toCharArray()) {
            if (cur.words[c - 'a'] == null) {
                cur.words[c - 'a'] = new Trie();
            }
            cur = cur.words[c - 'a'];
        }
        cur.isEnd = true;
    }

    public boolean search(String word) {
        Trie cur = this;
        for (char c : word.toCharArray()) {
            if (cur.words[c - 'a'] == null) return false;
            cur = cur.words[c - 'a'];
        }
        return cur.isEnd;
    }

    public boolean startsWith(String prefix) {
        Trie cur = this;
        for (char c : prefix.toCharArray()) {
            if (cur.words[c - 'a'] == null) return false;
            cur = cur.words[c - 'a'];
        }
        return true;
    }
}
</code></pre>
<h1 id="715">7.15</h1>
<h2 id="1-c-双端队列使用">1. C++ 双端队列使用</h2>
<p>使用到的类: <code>deque</code>。支持的方法: <code>front() , back() , pop_front() , pop_back()</code></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[论文写作-张老师分享]]></title>
        <id>https://saseke.github.io/post/lun-wen-xie-zuo-zhang-lao-shi-fen-xiang/</id>
        <link href="https://saseke.github.io/post/lun-wen-xie-zuo-zhang-lao-shi-fen-xiang/">
        </link>
        <updated>2022-06-18T07:24:00.000Z</updated>
        <content type="html"><![CDATA[<p><strong>问题驱动</strong></p>
<ol>
<li>我们要有一双发现问题的眼睛，要不断的去发现问题，提出问题。</li>
<li>在发现问题之后，我们紧跟着需要去解决问题。首先，我们需要问我们自己，自己如何去解决这个问题（要对自己有信心，相信自己可以解决）。其次，我们可以通过使用Goole搜索引擎去查找对应的解决方法。最后，我们可以询问自己的老师。在询问老师的过程中，我们需要注意一点，我们需要将问题高度凝练，向老师咨询这个问题自己究竟是哪里不会，而不是把一整个问题抛给老师。</li>
</ol>
<p><strong>如何读文献</strong><br>
我们要以问题为导向进行读文献，只要通过读文献，解决了自己问题就行。除此之外，我们需要明白文献背后作者想传达的思想。</p>
<p><strong>如何写毕业论文</strong></p>
<ol>
<li>我们可以每两周写一篇汇报。汇报的格式可以参考<strong>西电学报</strong>。通过平常的锻炼，可以大大提高我们编写论文的水平。<font color='red'>摘要通常是论文的最后才写。</font></li>
<li>在写毕业论文的过程中，我们可以把自己的思考过程，实验历程记录下来。这个记录的过程也是非常重要的。</li>
</ol>
<p><strong>如何寻找创新点</strong><br>
我们可以尝试着去考虑各种情况和问题，在极端或者各种问题的情况下，我们是否可以想出更好的办法去解决。---这个就是创新点产生的过程</p>
<p><strong>重点</strong><br>
自己写完一篇文章之后，隔一段时间，自己再去以完全不认识的心态去读自己写的文章。自己很有可能发现很多错误。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Distributed file system design]]></title>
        <id>https://saseke.github.io/post/distributed-file-system-design/</id>
        <link href="https://saseke.github.io/post/distributed-file-system-design/">
        </link>
        <updated>2022-06-14T07:42:34.000Z</updated>
        <content type="html"><![CDATA[<h1 id="文件系统构成">文件系统构成</h1>
<p>简单的文件系统主要由三部分构成：超级块，iNode,数据块</p>
<ol>
<li>超级块
<ol>
<li>iNode的位示图</li>
<li>dataNode的位示图</li>
<li>INode已经使用的数目</li>
<li>dataNode已经使用的数目</li>
</ol>
</li>
<li>INode:
<ol>
<li>所占用的所有磁盘块号</li>
<li>目录还是文件（文件的类型）</li>
<li>目录名称or文件名称</li>
<li>目录大小或者文件大小</li>
<li>权限信息</li>
<li>修改，更新时间</li>
</ol>
</li>
<li>DataNode:
<ol>
<li>文件数据内容</li>
<li>块数据的元数据: 校验和，生成戳(块的唯一标识)</li>
<li>有唯一的namespace ID,software版本（必须与NameNode版本一致）</li>
<li>盘块的唯一标识</li>
</ol>
</li>
</ol>
<h1 id="文件系统的功能">文件系统的功能</h1>
<ol>
<li>初始化文件系统
<ul>
<li>初始化超级块</li>
<li>确定namespace ID</li>
</ul>
</li>
<li>进入文件系统</li>
<li>退出文件系统</li>
<li>创建文件</li>
<li>删除文件</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[拓扑排序]]></title>
        <id>https://saseke.github.io/post/tuo-bu-pai-xu/</id>
        <link href="https://saseke.github.io/post/tuo-bu-pai-xu/">
        </link>
        <updated>2022-06-01T03:14:58.000Z</updated>
        <content type="html"><![CDATA[<p><strong>用途</strong><br>
检测图是否有环，分析学习课程是否能够全部完成<br>
<strong>原理</strong><br>
使用邻接表+BFS方法实现拓扑排序<br>
<strong>步骤</strong></p>
<ol>
<li>定义存储图的邻接矩阵<code>graph</code>，一个记录图中每个节点入度的集合<code>inEdge</code>，一个记录拓扑排序过程的集合<code>track</code></li>
<li>将图存储到邻接矩阵中，顺带将节点的入度信息存到入度集合中</li>
<li>使用BFS进行遍历入度为0的节点。定义一个queue 存储入度为0的节点。</li>
<li>每次从队列中弹出度为0的节点，删掉它的出去边的节点的入度信息，更新<code>inEdge</code>，判断节点的入度是否为0，如果为0，入<code>queue</code></li>
<li>如果需要获取轨迹，则返回<code>track</code>.如果判断是否构成一个拓扑排序，则判断<code>track.size()==n</code>即可<br>
<strong>代码示例</strong></li>
</ol>
<pre><code class="language-c++">bool canFinish(int numCourses, vector&lt;vector&lt;int&gt;&gt; &amp;prerequisites) {
    // 定义邻接矩阵，入度vector
    vector&lt;vector&lt;int&gt;&gt; graph(numCourses); // 定义邻接矩阵
    vector&lt;int&gt; inEdge(numCourses);  // 定义每个节点的入度
    vector&lt;int&gt; track;  // 定义拓扑排序访问元素的顺序 ,最后判断是否可以学习完，就看track的元素==numCourses
    // 将prerequisites中的数据存储到graph中,以及存储对应的入度信息
    for (auto courses: prerequisites) {
        int nextCourse = courses[0], preCourse = courses[1];
        graph[preCourse].push_back(nextCourse);
        inEdge[nextCourse]++;
    }
    // 使用bfs进行遍历入度为0的节点
    queue&lt;int&gt; q;
    // 将入度为0的节点放到queue中
    for (int i = 0; i &lt; numCourses; i++) {
        if (inEdge[i] == 0) q.push(i);
    }
    while (!q.empty()) {
        int node = q.front();
        q.pop();
        track.push_back(node);
        // 删掉node的所有出度对应的边
        for (auto e: graph[node]) {
            inEdge[e]--;
            if (inEdge[e] == 0) q.push(e);
        }
    }
    return track.size() == numCourses;
}
</code></pre>
<p><strong>题目</strong></p>
<ul>
<li><a href="https://leetcode.cn/problems/course-schedule/">LC207课程表</a></li>
<li><a href="https://mp.weixin.qq.com/s/pCRscwKqQdYYN7M1Sia7xA">检测循环依赖</a></li>
</ul>
]]></content>
    </entry>
</feed>